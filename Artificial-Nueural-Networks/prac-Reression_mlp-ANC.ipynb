{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c297c8b2-4e42-4b6f-8ee3-a72ae49023c4",
   "metadata": {},
   "source": [
    "# Building a Reression MLP Using the Sequential API\n",
    "In this prac session, we will be using the sequential API to build, train and evaluate a regressiion model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025da688-d3a6-4435-89ef-bab7b1f7daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb6b4ec-152f-466d-b868-c07cca7bc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - RootMeanSquaredError: 1.2487 - loss: 1.6826 - val_RootMeanSquaredError: 0.8225 - val_loss: 0.6766\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - RootMeanSquaredError: 0.6398 - loss: 0.4101 - val_RootMeanSquaredError: 0.9507 - val_loss: 0.9039\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - RootMeanSquaredError: 0.6086 - loss: 0.3709 - val_RootMeanSquaredError: 1.1594 - val_loss: 1.3441\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - RootMeanSquaredError: 0.5997 - loss: 0.3599 - val_RootMeanSquaredError: 1.0041 - val_loss: 1.0082\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - RootMeanSquaredError: 0.5872 - loss: 0.3451 - val_RootMeanSquaredError: 0.5701 - val_loss: 0.3250\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - RootMeanSquaredError: 0.5763 - loss: 0.3323 - val_RootMeanSquaredError: 0.9613 - val_loss: 0.9240\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - RootMeanSquaredError: 0.5707 - loss: 0.3259 - val_RootMeanSquaredError: 1.5114 - val_loss: 2.2844\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - RootMeanSquaredError: 0.5701 - loss: 0.3251 - val_RootMeanSquaredError: 0.8450 - val_loss: 0.7140\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - RootMeanSquaredError: 0.5613 - loss: 0.3153 - val_RootMeanSquaredError: 0.6470 - val_loss: 0.4186\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - RootMeanSquaredError: 0.5562 - loss: 0.3095 - val_RootMeanSquaredError: 1.0500 - val_loss: 1.1024\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - RootMeanSquaredError: 0.5548 - loss: 0.3079 - val_RootMeanSquaredError: 1.0209 - val_loss: 1.0422\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - RootMeanSquaredError: 0.5490 - loss: 0.3015 - val_RootMeanSquaredError: 0.6807 - val_loss: 0.4634\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - RootMeanSquaredError: 0.5445 - loss: 0.2966 - val_RootMeanSquaredError: 0.6721 - val_loss: 0.4518\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - RootMeanSquaredError: 0.5393 - loss: 0.2910 - val_RootMeanSquaredError: 0.5438 - val_loss: 0.2957\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - RootMeanSquaredError: 0.5356 - loss: 0.2869 - val_RootMeanSquaredError: 0.5768 - val_loss: 0.3327\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - RootMeanSquaredError: 0.5313 - loss: 0.2823 - val_RootMeanSquaredError: 0.5484 - val_loss: 0.3008\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - RootMeanSquaredError: 0.5289 - loss: 0.2797 - val_RootMeanSquaredError: 0.5723 - val_loss: 0.3276\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - RootMeanSquaredError: 0.5252 - loss: 0.2759 - val_RootMeanSquaredError: 0.5258 - val_loss: 0.2764\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - RootMeanSquaredError: 0.5218 - loss: 0.2723 - val_RootMeanSquaredError: 0.5945 - val_loss: 0.3535\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - RootMeanSquaredError: 0.5199 - loss: 0.2704 - val_RootMeanSquaredError: 0.5441 - val_loss: 0.2961\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - RootMeanSquaredError: 0.5302 - loss: 0.2813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd98d2b-a3a9-4843-bc70-89cab784f983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-neural",
   "language": "python",
   "name": "env-neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
