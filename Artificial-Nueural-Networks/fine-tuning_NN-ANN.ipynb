{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19e01d5-9323-44a4-a316-0ad8b0a66eb7",
   "metadata": {},
   "source": [
    "# Fine-tuning Neural Network Hyperparameters\n",
    "\n",
    " the flexilibility of neural networks is also one of it's main draw backs i.e there are so many hyperparameters to tweak i.e the number of layers, the number of neurons, the type of activation function to us in each layer, the weight initialization logic, the type of optimizers to use, its learning rate, the batch size and more\n",
    "\n",
    " **how do you you know what combination to hyperparameters is the best for your task?**\n",
    "\n",
    "* one option is to convert the keras model to a scikit-learn estimator and then use `GridSearchCV` and `RandomizedSearchCV` to finetune the hyperparameters.\n",
    "* alternatively is using the `Keras Tuner ` library whixh is a hyperparameter tuning library for Keras models. It offers several tuning strategies and it's highly customizable with an excellent integration with Tensor-board.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c459e83-a4b0-4cdc-9848-94d1ac5620cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf\n",
    "# fetch the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f556c5-3e02-4f60-a23a-d70184b78b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    # define the hyperparamters\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "    # build the model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10e877-18e3-4653-a65d-967a87d82884",
   "metadata": {},
   "source": [
    "To do a basic random search, one can create `kt.RandomSearch` tuner passing the `build_model` function th the constructor, and call the the tuner's `search()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fcdcabb-1f7a-4ed3-985a-f5c554f8e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 02s]\n",
      "val_accuracy: 0.004392764996737242\n",
      "\n",
      "Best val_accuracy So Far: 0.004392764996737242\n",
      "Total elapsed time: 00h 00m 10s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashio_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "\n",
    "random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa325eb-b4e0-4953-ae54-06620e0efdcd",
   "metadata": {},
   "source": [
    "Given the `objective` is set to `val_accurancy`, the tumer prefers models with a higher validation accuracy, so once the tuner has finished searching, one can get the best model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4609d8a-bbae-4606-8158-dbef5e793f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>]\n"
     ]
    }
   ],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]\n",
    "print(top3_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5620f8-8ecc-47ce-8549-7f812f632dad",
   "metadata": {},
   "source": [
    "one can also call `get_best_hyperparameters()` to get the kt.HyperParameters of the best models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eef3766c-b2fc-4de7-aa87-d4274197bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 25,\n",
       " 'learning_rate': 0.0006562536901904111,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "\n",
    "top3_params[0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf406da9-c2d3-4986-a89e-a717ff245262",
   "metadata": {},
   "source": [
    "Each tuner is guided by a so-called *oracle*: before each trial, the tuner asks the oracle to tell it what the next trial should be. The `RandomSearch` tuner uses a `RandomSearchOracle`, which is pretty basic: it just picks the next trial randomly, as we saw earlier. Since the oracle keeps track of all the trials, you can ask it to give you the best one, and you can display a summary of that trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb9d2b8f-4ea0-4427-9499-198ad4c053cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 5\n",
      "n_neurons: 25\n",
      "learning_rate: 0.0006562536901904111\n",
      "optimizer: sgd\n",
      "Score: 0.004392764996737242\n"
     ]
    }
   ],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a39a3-1b48-4917-ae71-e0e9b605ab8a",
   "metadata": {},
   "source": [
    "to show the best hyperparameters as well as the validation accuracy, you can also access all the metrics directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ccba8e-62d3-4514-a541-1bb788ce73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004392764996737242"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fad8d6-7b55-49d3-87b8-c5d1dff2efdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-neural",
   "language": "python",
   "name": "env-neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
