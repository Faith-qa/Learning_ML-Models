{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c92448-ef07-45c7-8a50-81ff90bf2385",
   "metadata": {},
   "source": [
    "## Behind the pipeline\n",
    "\n",
    "There are 3 stages in the pipeline:\n",
    "\n",
    "* Tokenizer\n",
    "* Model\n",
    "* PostProcessing\n",
    "\n",
    "\n",
    "*Process*\n",
    "\n",
    "**Raw Text** ====> **Numbers[Input IDs]** ====> **Outputs [Logits]** ===>\n",
    "**Predictions**\n",
    "\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "The process has several steps i.e: \n",
    "\n",
    "1. the text is split into small chunks called tokens\n",
    "2. it will add special tokens\n",
    "3. matches each token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea692b9-6297-466a-b032-82d489cc2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from tensorflow) (70.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "absl-py==2.1.0\n",
      "anyio==4.4.0\n",
      "appnope==0.1.4\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "attrs==23.2.0\n",
      "Babel==2.15.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "certifi==2024.7.4\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "comm==0.2.2\n",
      "debugpy==1.8.2\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.20.0\n",
      "filelock==3.15.4\n",
      "flatbuffers==24.3.25\n",
      "fqdn==1.5.1\n",
      "fsspec==2024.6.1\n",
      "gast==0.6.0\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.64.1\n",
      "h11==0.14.0\n",
      "h5py==3.11.0\n",
      "httpcore==1.0.5\n",
      "httpx==0.27.0\n",
      "huggingface-hub==0.23.4\n",
      "idna==3.7\n",
      "ipykernel==6.29.5\n",
      "ipython==8.26.0\n",
      "ipywidgets==8.1.3\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "json5==0.9.25\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.2\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.3\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.2\n",
      "jupyterlab_widgets==3.0.11\n",
      "keras==3.4.1\n",
      "libclang==18.1.1\n",
      "Markdown==3.6\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mistune==3.0.2\n",
      "ml-dtypes==0.4.0\n",
      "namex==0.0.8\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "notebook==7.2.1\n",
      "notebook_shim==0.2.4\n",
      "numpy==1.26.4\n",
      "opt-einsum==3.3.0\n",
      "optree==0.12.1\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "platformdirs==4.2.2\n",
      "prometheus_client==0.20.0\n",
      "prompt_toolkit==3.0.47\n",
      "protobuf==4.25.3\n",
      "psutil==6.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pycparser==2.22\n",
      "Pygments==2.18.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==2.0.7\n",
      "PyYAML==6.0.1\n",
      "pyzmq==26.0.3\n",
      "qtconsole==5.5.2\n",
      "QtPy==2.4.1\n",
      "referencing==0.35.1\n",
      "regex==2024.5.15\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.7.1\n",
      "rpds-py==0.19.0\n",
      "safetensors==0.4.3\n",
      "Send2Trash==1.8.3\n",
      "setuptools==70.3.0\n",
      "six==1.16.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.5\n",
      "stack-data==0.6.3\n",
      "tensorboard==2.17.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.17.0\n",
      "termcolor==2.4.0\n",
      "terminado==0.18.1\n",
      "tinycss2==1.3.0\n",
      "tokenizers==0.19.1\n",
      "tornado==6.4.1\n",
      "tqdm==4.66.4\n",
      "traitlets==5.14.3\n",
      "transformers==4.42.4\n",
      "types-python-dateutil==2.9.0.20240316\n",
      "typing_extensions==4.12.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.2\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.6.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "Werkzeug==3.0.3\n",
      "wheel==0.43.0\n",
      "widgetsnbextension==4.0.11\n",
      "wrapt==1.16.0\n"
     ]
    }
   ],
   "source": [
    "# install the required dependencies in the virtual environment venv\n",
    "\n",
    "# install tensorflow\n",
    "\n",
    "!pip install tensorflow\n",
    "!pip freeze > requirements.txt\n",
    "!cat requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02d7983-24f1-49d5-ae6c-307cfe861808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6056df6684b54cd2ac16b91be7251390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eae0a4a77974f27ae8107457eb4c136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9d033948cd4ce983be80d761daa945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "print(\"hello\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f689f6-7a40-452b-9679-2d400a8e98d0",
   "metadata": {},
   "source": [
    "## Pipeline process explained\n",
    "\n",
    "it groups together 3 steps:\n",
    "* tokenizer\n",
    "* model\n",
    "* post processing\n",
    "\n",
    "### preprocessing with tokenizer\n",
    "\n",
    "1. test input is converted to numbers that the model can make sense of using `tokenizers` responsible for : splitting input, mapping each token to integer and adding additional inputs that may be usefull to the model\n",
    "\n",
    "2. preprocessing needs to be done in the exact same way the model was pretrained. to achieve this, the `AutoTokenizer class` and its `from_pretranined()` method is used. Using the checkpoint name of the model, it will automatically fetch the data associated with the model tokenizer and cache it such that it is only downloaded once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2d47ca-06eb-4b34-88a0-b3314abe54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the autotokenizer class\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb2619-5012-4575-add5-5d8197509a43",
   "metadata": {},
   "source": [
    "3. once the tokenizer is created as above:- sentences can be passed. output will be a dictionary that's ready to feed to the model\n",
    "4. convert list of input id's to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dc8e98-d1c2-4992-a34c-9a80ab5c4f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
      "array([[ 101, 1045, 1005, 2310, 2042, 3403, 2005, 2023, 2607, 2026, 2878,\n",
      "        2166,  102],\n",
      "       [ 101, 1045, 5223, 2023, 2061, 2172,  999,  102,    0,    0,    0,\n",
      "           0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "raw_inputs = [\n",
    "    \"i've been waiting for this course my whole life\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3b318-28c7-4099-b3be-691013ebce62",
   "metadata": {},
   "source": [
    "**Going through the model**\n",
    "\n",
    "we can download the pretrained model the same way i.e transformers provides a `TFAutoModel` class which equally has a `from_pretrained` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1eddf5f-26dc-4a5d-90c5-2b4821c600f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273dc7a0e5fb43bfab65bfda38df0c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = TFAutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625511ae-46c4-4f0a-9f29-813e57907381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
