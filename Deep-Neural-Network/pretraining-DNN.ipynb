{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a88b84-c754-477d-8ab0-38fc73fad6b5",
   "metadata": {},
   "source": [
    "# Reusing Pretrained Layers\n",
    "*transfer learning*- using an already trained DNN layers except for the top ones. involves finding an existing neural network that accomplishes a similar task to the one you are trying to tackle\n",
    "\n",
    "let'a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "babfb6d9-1e82-46b5-9072-aadf58ca568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.5273 - loss: 1.4999 - val_accuracy: 0.8002 - val_loss: 0.6796\n",
      "Epoch 2/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - accuracy: 0.8046 - loss: 0.6340 - val_accuracy: 0.8441 - val_loss: 0.4941\n",
      "Epoch 3/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.8497 - loss: 0.4824 - val_accuracy: 0.8631 - val_loss: 0.4198\n",
      "Epoch 4/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.8668 - loss: 0.4131 - val_accuracy: 0.8716 - val_loss: 0.3800\n",
      "Epoch 5/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.8757 - loss: 0.3732 - val_accuracy: 0.8792 - val_loss: 0.3560\n",
      "Epoch 6/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.8823 - loss: 0.3479 - val_accuracy: 0.8824 - val_loss: 0.3399\n",
      "Epoch 7/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.8864 - loss: 0.3300 - val_accuracy: 0.8857 - val_loss: 0.3280\n",
      "Epoch 8/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.8904 - loss: 0.3165 - val_accuracy: 0.8887 - val_loss: 0.3187\n",
      "Epoch 9/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.8934 - loss: 0.3057 - val_accuracy: 0.8910 - val_loss: 0.3109\n",
      "Epoch 10/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.8960 - loss: 0.2967 - val_accuracy: 0.8920 - val_loss: 0.3044\n",
      "Epoch 11/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - accuracy: 0.8984 - loss: 0.2891 - val_accuracy: 0.8950 - val_loss: 0.2987\n",
      "Epoch 12/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.9014 - loss: 0.2824 - val_accuracy: 0.8960 - val_loss: 0.2939\n",
      "Epoch 13/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.9037 - loss: 0.2766 - val_accuracy: 0.8977 - val_loss: 0.2896\n",
      "Epoch 14/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.9062 - loss: 0.2713 - val_accuracy: 0.9000 - val_loss: 0.2857\n",
      "Epoch 15/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.9075 - loss: 0.2665 - val_accuracy: 0.9015 - val_loss: 0.2823\n",
      "Epoch 16/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.9086 - loss: 0.2621 - val_accuracy: 0.9040 - val_loss: 0.2790\n",
      "Epoch 17/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.9094 - loss: 0.2581 - val_accuracy: 0.9040 - val_loss: 0.2760\n",
      "Epoch 18/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.9110 - loss: 0.2543 - val_accuracy: 0.9050 - val_loss: 0.2731\n",
      "Epoch 19/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460us/step - accuracy: 0.9120 - loss: 0.2508 - val_accuracy: 0.9047 - val_loss: 0.2705\n",
      "Epoch 20/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.9141 - loss: 0.2474 - val_accuracy: 0.9050 - val_loss: 0.2680\n"
     ]
    }
   ],
   "source": [
    "# create a sample model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                      validation_data=(X_valid_A, y_valid_A))\n",
    "model_A.save(\"my_model_A.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebae9a31-b0ed-4548-a641-d753fcc78525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the model\n",
    "\n",
    "modelA = tf.keras.models.load_model(\"my_model_A.keras\")\n",
    "model_B_on_A = tf.keras.Sequential(modelA.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f0646-32db-4f6e-8ab6-8aef43585ef9",
   "metadata": {},
   "source": [
    "from the above, `modelA` and `model_B_on_A` now share some layers. When one trains `model_B_on_A`, it will also affect `modelA`.\n",
    "\n",
    "to avoid that, we need to clone the model before reusing its layers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5cb26af-542c-48e4-b00c-58254d78a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = tf.keras.models.clone_model(modelA)\n",
    "model_A_clone.set_weights(modelA.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48fe19-4d11-4474-9ff5-bee079429926",
   "metadata": {},
   "source": [
    "\n",
    "`tf.keras.models.clone_model()` only clones the architecture, not the weights. If you don’t copy them manually using set_weights(), they will be initialized randomly when the cloned model is first used.\n",
    "\n",
    "let's recreate model_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6408df3e-4b59-44f4-b357-e5fae44f6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83eddcb7-de99-48a3-9fdc-b4dc0474249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30397712-2407-4715-a60d-7cd40db44e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5699 - loss: 1.3129 - val_accuracy: 0.4857 - val_loss: 0.9044\n",
      "Epoch 2/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5382 - loss: 0.7619 - val_accuracy: 0.4936 - val_loss: 0.7378\n",
      "Epoch 3/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5217 - loss: 0.6696 - val_accuracy: 0.5371 - val_loss: 0.7118\n",
      "Epoch 4/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 0.6552 - val_accuracy: 0.5559 - val_loss: 0.6975\n",
      "Epoch 1/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6153 - loss: 0.6309 - val_accuracy: 0.6588 - val_loss: 0.6197\n",
      "Epoch 2/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.5585 - val_accuracy: 0.7240 - val_loss: 0.5569\n",
      "Epoch 3/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 0.4987 - val_accuracy: 0.7725 - val_loss: 0.5064\n",
      "Epoch 4/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4510 - val_accuracy: 0.8190 - val_loss: 0.4654\n",
      "Epoch 5/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.4126 - val_accuracy: 0.8467 - val_loss: 0.4317\n",
      "Epoch 6/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.3809 - val_accuracy: 0.8714 - val_loss: 0.4037\n",
      "Epoch 7/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.3546 - val_accuracy: 0.8853 - val_loss: 0.3804\n",
      "Epoch 8/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3329 - val_accuracy: 0.8981 - val_loss: 0.3609\n",
      "Epoch 9/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3146 - val_accuracy: 0.9060 - val_loss: 0.3444\n",
      "Epoch 10/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.2993 - val_accuracy: 0.9090 - val_loss: 0.3303\n",
      "Epoch 11/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.2862 - val_accuracy: 0.9130 - val_loss: 0.3179\n",
      "Epoch 12/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2746 - val_accuracy: 0.9169 - val_loss: 0.3072\n",
      "Epoch 13/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2647 - val_accuracy: 0.9209 - val_loss: 0.2980\n",
      "Epoch 14/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.2560 - val_accuracy: 0.9228 - val_loss: 0.2897\n",
      "Epoch 15/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2483 - val_accuracy: 0.9238 - val_loss: 0.2823\n",
      "Epoch 16/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.2413 - val_accuracy: 0.9258 - val_loss: 0.2757\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                    validation_data=(X_valid_B, y_valid_B))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a144865-e6e0-49a0-8815-525a1ad873a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.9125 - loss: 0.2900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29054635763168335, 0.9120000004768372]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "model_B_on_A.evaluate(X_test_B, y_test_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15618a12-ebb3-483d-9439-05dfab433408",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-DNN",
   "language": "python",
   "name": "env-dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
