{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14c6e30-3c08-478c-82d7-2a615c9318d5",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks\n",
    "\n",
    "challenges with training deep neural networks:\n",
    "\n",
    "- gradients rowing smaller or larger during training. this makes lower layers very hard to train\n",
    "- small training data i.e too costly to labrl\n",
    "- a model with millions of parameters has a higher risk of over fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c768d-dcc3-49c6-ad23-0ea13b6ccba5",
   "metadata": {},
   "source": [
    "## the Vanishing/Exploding Gradients problem\n",
    "\n",
    "gradients often get smaller and smaller as the algorithm progresses down to the lower layers. the gradient descent update leaves the lower layer's connection weights virtually unchanged and the training never converges to a good sollution. this is called the *vanishing gradients problem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e134f9-6898-47e7-bd85-649a571338ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dense = tf.keras.layers.Dense(50, activation=\"relu\", \n",
    "                              kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d7f70-327b-413b-b6bf-d678ddda9246",
   "metadata": {},
   "source": [
    "### better activation function\n",
    "\n",
    "problems with unstable gradients were partly due to a poor choice in activation functions. most people assumed that if mother nature had chosen to use roughly sigmoid activation functions in biological neurons, they must be an excellent choice\n",
    "\n",
    "however it turns out there are betty activation functions that behave better in neural networks i.e `the ReLU activation function` because it does not saturate the positive values and it is fast to compute\n",
    "\n",
    "the **ReLU activation function is not perfect** it suffers from a problem known as the **the dying relu** where during training some neurons effectively 'die' i.e they stop outputting anything other than 0. this happens especially when one uses a large learning rate. \n",
    "\n",
    "A neuron dies when it's weights gets tweeked in such a way that the input of the ReLU function i.e the weighted sum of the neurons inputs plus it's bias term is negative for all instances in the training set.\n",
    "when this happens, it just keeps outputing zeross and gradient decent does not affect it anymore given it is zero when input is negative\n",
    "\n",
    "To fix this, one can use a variant of the ReLU function, i.e the leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1ae70-b546-4157-930c-0ef5d0d23b75",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-DNN",
   "language": "python",
   "name": "env-dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
